# Tauron — CLAUDE.md

Cornell Digital Ag Hackathon · Feb 27–Mar 1, 2026 · $8,000 Prize Pool
GNN early-warning system for dairy herd disease detection.

---

## Repo Layout

```
Tauron/
├── brief.html          # Project brief (full spec)
├── slides.html         # Pitch deck
├── tauron_ml.ipynb     # Full ML pipeline (primary ML work lives here)
├── api.py              # FastAPI backend (generated by notebook, gitignored)
├── venv/               # Python 3.9 virtual environment (gitignored)
├── data/               # Generated datasets + plots (gitignored)
└── models/             # Saved model checkpoints (gitignored)
```

**Branches**
- `main` — frontend/pitch materials
- `ml-pipeline` — all ML and backend work

---

## Environment

```bash
# Activate venv
source venv/bin/activate

# Launch notebook (kernel: "Tauron ML")
jupyter lab tauron_ml.ipynb

# Start FastAPI (after running notebook to generate api.py)
uvicorn api:app --reload

# Python version
python3.9
```

**Key packages:** `torch 2.8`, `torch_geometric 2.6.1`, `fastapi`, `anthropic`, `pandas`, `scikit-learn`, `matplotlib`

---

## ML Architecture

```
x_seq [N, T=7, F=14]
       │
    GRU (hidden=128)          ← temporal: 7-day rolling window per cow
       │
    SAGEConv × 2 (2-hop)      ← graph: neighbourhood aggregation
       │
    Linear → Sigmoid × 3      ← 3-head decoder
       │
    risk [N, 3]               ← mastitis | BRD | lameness (T+48h)
```

**Loss:** Binary cross-entropy
**Optimizer:** Adam + cosine LR schedule
**Saved checkpoint:** `models/tauron_model.pt`

---

## Data Tiers

| Tier | Source | Features | Target AUROC |
|------|--------|----------|-------------|
| 1 | Manual / CSV | milk yield, vet log, pen ID, feeding visits, DIM | ~55% |
| 2 | Automated milking API | + conductivity, milking freq/duration, weight | ~74% |
| 3 | Wearable collars (SCR/Allflex) | + rumination, activity, proximity, temp, lying | ~89% |

Lower tiers are zero-padded to the full 14-feature vector — one model serves all tiers.

---

## Graph Construction

- **Nodes:** each cow; node features = 7-day rolling window of all metrics
- **Pen edges:** cows sharing a pen → weight 1.0
- **Bunk edges:** cows at the same feeding station → weight = co-visit frequency
- Graph rebuilt every 24 h (or 6 h with wearables)

---

## Key Functions (`tauron_ml.ipynb`)

| Function | Purpose |
|----------|---------|
| `ingest_csv(path, tier)` | Load farm CSV, normalise to long format |
| `ingest_manual(entries)` | 5-field manual entry → normalised DataFrame |
| `ingest_api(source)` | DeLaval / Lely / GEA stub |
| `build_graph(farm_df, date)` | Farm records → PyG `Data` object |
| `inject_disease(graph, disease)` | Synthetic label generation via contagion propagation |
| `generate_labels(graph)` | Returns `[N, 3]` label tensor for a snapshot |
| `build_dataset(farm_df, n_runs)` | Builds 500+ labelled snapshots → `data/dataset.pt` |
| `predict(graph)` | `cow_id → {mastitis, brd, lameness}` risk scores |
| `explain_cow(graph, cow_idx)` | GNNExplainer → structured XAI JSON |
| `stage_demo_event(farm_df)` | Injects Cow #47 mastitis event for demo |

---

## API Endpoints (`api.py`)

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/herd` | All cow risk scores + graph edges |
| `GET` | `/alert/{cow_id}` | GNNExplainer JSON for one cow |
| `GET` | `/explain/{cow_id}` | Claude API plain-English farmer alert |
| `POST` | `/api/ingest` | CSV / JSON / manual data ingestion |

Set `ANTHROPIC_API_KEY` in environment for the `/explain` endpoint.

---

## Demo Script (Hackathon)

1. Open `localhost:3000` (React frontend)
2. Navigate to Herd Map — 60 cows, force-directed D3 graph
3. Point to **Cow #47** — amber node, edges glowing to pen-mates
4. Click → alert card: *"Cow #47 — high mastitis risk. Milk yield dropped 18%…"*
5. Show Tier upgrade nudge on Sustainability screen

**Staged event:** `stage_demo_event(FARM_DF, patient_zero_id=47, event_date_str='2026-01-13')`

---

## Wageningen Dataset

Real data available at: `https://data.mendeley.com/datasets/hn7xm6ndgj` (free Mendeley account)
Currently using a synthetic stand-in with identical statistical profile.
To swap in: replace `FARM_DF = generate_synthetic_farm()` in Section 01 of the notebook with `FARM_DF = pd.read_csv('data/wageningen.csv')`.

---

## What NOT to do

- Do not commit `venv/`, `data/`, `models/`, or `api.py` — all gitignored
- Do not `git push` to `main` without checking with the team
- Do not add frontend changes to `ml-pipeline` branch
- Do not hardcode `ANTHROPIC_API_KEY` anywhere
